{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagina donde encontrar modelos de IA\n",
    "\n",
    "https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers\n",
    "#!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oscar.torresrodrigue\\AppData\\Local\\miniconda3\\envs\\tracking\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "# Comprobar si hay una GPU disponible\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "# https://huggingface.co/docs/transformers/main_classes/logging\n",
    "transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1 star, with score: 0.6107\n",
      "label: 3 stars, with score: 0.3773\n",
      "label: 5 stars, with score: 0.3502\n"
     ]
    }
   ],
   "source": [
    "# análisis sentimiento\n",
    "from transformers import pipeline\n",
    "nlp = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\", device=device)\n",
    "\n",
    "# Analizar el sentimiento del texto\n",
    "result = nlp(\"vi cosas peores\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "# Analizar el sentimiento del texto\n",
    "result = nlp(\"No estaba nada mal\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "# Analizar el sentimiento del texto\n",
    "result = nlp(\"mejor dar un paseo\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Everything went wrong.'}]\n"
     ]
    }
   ],
   "source": [
    "# traducción\n",
    "from transformers import pipeline\n",
    "\n",
    "# https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200\n",
    "nlp = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\", src_lang=\"spa_Latn\", tgt_lang=\"eng_Latn\")\n",
    "# traducción del texto\n",
    "result = nlp(\"todo se estropeó\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oscar.torresrodrigue\\AppData\\Local\\miniconda3\\envs\\tracking\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Hace unos meses, la revista británica The Guardian publicó una serie de reportes sobre el negocio de los pollos.'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Hace unos meses, la revista británica The New York Times publicó un reportaje sobre el negocio de los La muchacha, cuyo padre era lechero, se rompió y con él se fueron la ternera, la vaca, el cerdo y los pollos'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resumen\n",
    "nlp = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\", device=device)\n",
    "\n",
    "texto=\"\"\"\n",
    "Había una vez una muchacha, cuyo padre era lechero, con un cántaro de leche en la cabeza.\n",
    "Caminaba ligera y dando grandes zancadas para llegar lo antes posible a la ciudad, a donde iba para vender la lec\n",
    "Por el camino empezó a pensar lo que haría con el dinero que le darían a cambio de la leche.\n",
    "-Compraré un centenar de huevos. O no, mejor tres pollos. ¡Sí, compraré tres pollos!\n",
    "La muchacha seguía adelante poniendo cuidado de no tropezar mientras su imaginación iba cada vez más y más lejos.\n",
    "-Criaré los pollos y tendré cada vez más, y aunque aparezca por ahí el zorro y mate algunos, seguro que tengo suficiente.\n",
    "Pero de repente, la muchacha tropezó, el cántaro se rompió y con él se fueron la ternera, la vaca, el cerdo y los\n",
    "\"\"\"\n",
    "\n",
    "resumen = nlp(texto)\n",
    "print(resumen)\n",
    "del nlp \n",
    "\n",
    "[{'summary_text': 'Hace unos meses, la revista británica The New York Times publicó un reportaje sobre el negocio de los La muchacha, cuyo padre era lechero, se rompió y con él se fueron la ternera, la vaca, el cerdo y los pollos'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La muchacha, que se rompió y con él se fueron la ternera, la vaca, el cerdo y los pollos, entre otros'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# otra prueba con otro\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckpt = 'mrm8488/bert2bert_shared-spanish-finetuned-summarization'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(ckpt)\n",
    "model = EncoderDecoderModel.from_pretrained(ckpt).to(device)\n",
    "\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "generate_summary(texto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
