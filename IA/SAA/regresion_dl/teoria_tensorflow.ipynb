{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargamos el dataset que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "print(housing[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos del dataset lo que seran nuestras x e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacemos la division de los datos que tenemos, entre train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizamos el standar escaler para crear datos homogeneos\n",
    "\n",
    "Acordarse de separa los datos de train y test, con el fit_transform y con el transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.599  , 1.663  , 1.438  , ..., 5.00001, 3.297  , 0.678  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Modos para crear las redes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos el modelo del keras.models de la siguiente forma\n",
    "\n",
    "1.- Modo Secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se le pasa una lista con las capas que queramos\n",
    "model = keras.models.Sequential([\n",
    "    # En el shape casisiempre se le pasan tuplas\n",
    "    keras.layers.Input(shape=(8,)),\n",
    "    # Aqui le indicamos la cantidad de neuronas\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    #Esta linea substituiria a las dos anteriores\n",
    "    # keras.layers.Dense(30, activation=\"relu\", input_shape=(8,)),\n",
    "    # \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.001))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.-Modo Funcional\n",
    "\n",
    "Sirve para arquitecturas mas sofisticadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Api funcional\n",
    "\n",
    "# A cada capa se le va pasando la anterior\n",
    "inputs = keras.Input((8,))\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(inputs)\n",
    "outputs = keras.layers.Dense(1)(hidden1)\n",
    "model = keras.models.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Modelo de subclase\n",
    "\n",
    "Recomienda hacerlo con pytorch que con keras, no es recomendable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api subclase\n",
    "class RegCalifornia(keras.models.Model):\n",
    "    def __init__(self,shape=X_train.shape[1:], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"relu\")\n",
    "        self.outputs = keras.layers.Dense(1)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h1 = self.hidden1(inputs)\n",
    "        outputs = self.outputs(h1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red\n",
    "\n",
    "Le pasamos los datos para el entrenamiento, el numero de vueltas que le va a dar y los datos de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3949 - val_loss: 0.4055\n",
      "Epoch 2/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3942 - val_loss: 0.4047\n",
      "Epoch 3/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.3934 - val_loss: 0.4039\n",
      "Epoch 4/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3926 - val_loss: 0.4031\n",
      "Epoch 5/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3919 - val_loss: 0.4024\n",
      "Epoch 6/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3912 - val_loss: 0.4017\n",
      "Epoch 7/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3904 - val_loss: 0.4009\n",
      "Epoch 8/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3897 - val_loss: 0.4003\n",
      "Epoch 9/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3891 - val_loss: 0.3996\n",
      "Epoch 10/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3884 - val_loss: 0.3989\n",
      "Epoch 11/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.3877 - val_loss: 0.3983\n",
      "Epoch 12/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3871 - val_loss: 0.3977\n",
      "Epoch 13/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3864 - val_loss: 0.3971\n",
      "Epoch 14/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3858 - val_loss: 0.3964\n",
      "Epoch 15/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3852 - val_loss: 0.3959\n",
      "Epoch 16/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3846 - val_loss: 0.3953\n",
      "Epoch 17/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3840 - val_loss: 0.3948\n",
      "Epoch 18/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3835 - val_loss: 0.3943\n",
      "Epoch 19/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.3829 - val_loss: 0.3938\n",
      "Epoch 20/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3824 - val_loss: 0.3933\n",
      "Epoch 21/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3818 - val_loss: 0.3928\n",
      "Epoch 22/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3813 - val_loss: 0.3924\n",
      "Epoch 23/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.3808 - val_loss: 0.3919\n",
      "Epoch 24/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3803 - val_loss: 0.3914\n",
      "Epoch 25/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3798 - val_loss: 0.3910\n",
      "Epoch 26/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3793 - val_loss: 0.3906\n",
      "Epoch 27/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3789 - val_loss: 0.3902\n",
      "Epoch 28/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3784 - val_loss: 0.3898\n",
      "Epoch 29/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3780 - val_loss: 0.3894\n",
      "Epoch 30/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3776 - val_loss: 0.3891\n",
      "Epoch 31/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.3771 - val_loss: 0.3887\n",
      "Epoch 32/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3767 - val_loss: 0.3883\n",
      "Epoch 33/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3763 - val_loss: 0.3880\n",
      "Epoch 34/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3760 - val_loss: 0.3876\n",
      "Epoch 35/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3756 - val_loss: 0.3873\n",
      "Epoch 36/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3752 - val_loss: 0.3870\n",
      "Epoch 37/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3749 - val_loss: 0.3866\n",
      "Epoch 38/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.3745 - val_loss: 0.3863\n",
      "Epoch 39/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3742 - val_loss: 0.3860\n",
      "Epoch 40/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3739 - val_loss: 0.3857\n",
      "Epoch 41/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3735 - val_loss: 0.3854\n",
      "Epoch 42/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3732 - val_loss: 0.3851\n",
      "Epoch 43/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3729 - val_loss: 0.3849\n",
      "Epoch 44/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.3726 - val_loss: 0.3846\n",
      "Epoch 45/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3723 - val_loss: 0.3843\n",
      "Epoch 46/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3720 - val_loss: 0.3840\n",
      "Epoch 47/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3717 - val_loss: 0.3837\n",
      "Epoch 48/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3714 - val_loss: 0.3834\n",
      "Epoch 49/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3711 - val_loss: 0.3831\n",
      "Epoch 50/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3708 - val_loss: 0.3829\n",
      "Epoch 51/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3705 - val_loss: 0.3826\n",
      "Epoch 52/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3702 - val_loss: 0.3823\n",
      "Epoch 53/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3699 - val_loss: 0.3820\n",
      "Epoch 54/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.3696 - val_loss: 0.3818\n",
      "Epoch 55/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3694 - val_loss: 0.3815\n",
      "Epoch 56/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3691 - val_loss: 0.3812\n",
      "Epoch 57/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3688 - val_loss: 0.3810\n",
      "Epoch 58/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3685 - val_loss: 0.3807\n",
      "Epoch 59/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3683 - val_loss: 0.3805\n",
      "Epoch 60/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.3680 - val_loss: 0.3802\n",
      "Epoch 61/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3677 - val_loss: 0.3800\n",
      "Epoch 62/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.3675 - val_loss: 0.3798\n",
      "Epoch 63/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.3672 - val_loss: 0.3795\n",
      "Epoch 64/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3670 - val_loss: 0.3793\n",
      "Epoch 65/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3667 - val_loss: 0.3791\n",
      "Epoch 66/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3665 - val_loss: 0.3788\n",
      "Epoch 67/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3662 - val_loss: 0.3786\n",
      "Epoch 68/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3660 - val_loss: 0.3784\n",
      "Epoch 69/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3657 - val_loss: 0.3782\n",
      "Epoch 70/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3655 - val_loss: 0.3780\n",
      "Epoch 71/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3652 - val_loss: 0.3777\n",
      "Epoch 72/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3650 - val_loss: 0.3775\n",
      "Epoch 73/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3648 - val_loss: 0.3773\n",
      "Epoch 74/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3645 - val_loss: 0.3771\n",
      "Epoch 75/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3643 - val_loss: 0.3769\n",
      "Epoch 76/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3641 - val_loss: 0.3767\n",
      "Epoch 77/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - loss: 0.3638 - val_loss: 0.3765\n",
      "Epoch 78/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3636 - val_loss: 0.3763\n",
      "Epoch 79/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3634 - val_loss: 0.3761\n",
      "Epoch 80/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3632 - val_loss: 0.3759\n",
      "Epoch 81/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3630 - val_loss: 0.3757\n",
      "Epoch 82/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3627 - val_loss: 0.3755\n",
      "Epoch 83/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3625 - val_loss: 0.3753\n",
      "Epoch 84/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.3623 - val_loss: 0.3751\n",
      "Epoch 85/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3621 - val_loss: 0.3749\n",
      "Epoch 86/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3618 - val_loss: 0.3747\n",
      "Epoch 87/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3616 - val_loss: 0.3745\n",
      "Epoch 88/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3614 - val_loss: 0.3744\n",
      "Epoch 89/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3612 - val_loss: 0.3742\n",
      "Epoch 90/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3610 - val_loss: 0.3740\n",
      "Epoch 91/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3608 - val_loss: 0.3738\n",
      "Epoch 92/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3606 - val_loss: 0.3736\n",
      "Epoch 93/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3603 - val_loss: 0.3734\n",
      "Epoch 94/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3601 - val_loss: 0.3732\n",
      "Epoch 95/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3599 - val_loss: 0.3730\n",
      "Epoch 96/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3597 - val_loss: 0.3729\n",
      "Epoch 97/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3595 - val_loss: 0.3727\n",
      "Epoch 98/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3593 - val_loss: 0.3725\n",
      "Epoch 99/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3591 - val_loss: 0.3724\n",
      "Epoch 100/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3589 - val_loss: 0.3722\n",
      "Epoch 101/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3587 - val_loss: 0.3721\n",
      "Epoch 102/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3585 - val_loss: 0.3719\n",
      "Epoch 103/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3583 - val_loss: 0.3718\n",
      "Epoch 104/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3581 - val_loss: 0.3717\n",
      "Epoch 105/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3579 - val_loss: 0.3715\n",
      "Epoch 106/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3577 - val_loss: 0.3713\n",
      "Epoch 107/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3575 - val_loss: 0.3712\n",
      "Epoch 108/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3573 - val_loss: 0.3711\n",
      "Epoch 109/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3571 - val_loss: 0.3709\n",
      "Epoch 110/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3570 - val_loss: 0.3708\n",
      "Epoch 111/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3568 - val_loss: 0.3707\n",
      "Epoch 112/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3566 - val_loss: 0.3705\n",
      "Epoch 113/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3564 - val_loss: 0.3704\n",
      "Epoch 114/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3562 - val_loss: 0.3702\n",
      "Epoch 115/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3560 - val_loss: 0.3701\n",
      "Epoch 116/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.3558 - val_loss: 0.3700\n",
      "Epoch 117/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3556 - val_loss: 0.3698\n",
      "Epoch 118/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.3554 - val_loss: 0.3697\n",
      "Epoch 119/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.3552 - val_loss: 0.3696\n",
      "Epoch 120/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3550 - val_loss: 0.3695\n",
      "Epoch 121/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.3548 - val_loss: 0.3694\n",
      "Epoch 122/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.3546 - val_loss: 0.3692\n",
      "Epoch 123/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3544 - val_loss: 0.3690\n",
      "Epoch 124/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.3542 - val_loss: 0.3689\n",
      "Epoch 125/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.3541 - val_loss: 0.3687\n",
      "Epoch 126/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3539 - val_loss: 0.3686\n",
      "Epoch 127/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3537 - val_loss: 0.3684\n",
      "Epoch 128/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3535 - val_loss: 0.3682\n",
      "Epoch 129/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3533 - val_loss: 0.3680\n",
      "Epoch 130/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3531 - val_loss: 0.3679\n",
      "Epoch 131/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3529 - val_loss: 0.3677\n",
      "Epoch 132/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3528 - val_loss: 0.3675\n",
      "Epoch 133/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3526 - val_loss: 0.3673\n",
      "Epoch 134/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3524 - val_loss: 0.3672\n",
      "Epoch 135/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3522 - val_loss: 0.3670\n",
      "Epoch 136/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3520 - val_loss: 0.3668\n",
      "Epoch 137/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3518 - val_loss: 0.3666\n",
      "Epoch 138/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3517 - val_loss: 0.3664\n",
      "Epoch 139/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3515 - val_loss: 0.3663\n",
      "Epoch 140/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3513 - val_loss: 0.3661\n",
      "Epoch 141/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.3511 - val_loss: 0.3659\n",
      "Epoch 142/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.3509 - val_loss: 0.3657\n",
      "Epoch 143/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3507 - val_loss: 0.3656\n",
      "Epoch 144/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.3505 - val_loss: 0.3654\n",
      "Epoch 145/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3503 - val_loss: 0.3653\n",
      "Epoch 146/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3501 - val_loss: 0.3651\n",
      "Epoch 147/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3499 - val_loss: 0.3649\n",
      "Epoch 148/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3498 - val_loss: 0.3647\n",
      "Epoch 149/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.3496 - val_loss: 0.3646\n",
      "Epoch 150/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3494 - val_loss: 0.3644\n",
      "Epoch 151/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3492 - val_loss: 0.3642\n",
      "Epoch 152/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.3490 - val_loss: 0.3641\n",
      "Epoch 153/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3488 - val_loss: 0.3639\n",
      "Epoch 154/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3487 - val_loss: 0.3638\n",
      "Epoch 155/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3485 - val_loss: 0.3636\n",
      "Epoch 156/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3483 - val_loss: 0.3634\n",
      "Epoch 157/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3482 - val_loss: 0.3633\n",
      "Epoch 158/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3480 - val_loss: 0.3631\n",
      "Epoch 159/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3478 - val_loss: 0.3629\n",
      "Epoch 160/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.3476 - val_loss: 0.3628\n",
      "Epoch 161/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3474 - val_loss: 0.3626\n",
      "Epoch 162/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3473 - val_loss: 0.3625\n",
      "Epoch 163/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3471 - val_loss: 0.3623\n",
      "Epoch 164/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3469 - val_loss: 0.3622\n",
      "Epoch 165/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.3468 - val_loss: 0.3621\n",
      "Epoch 166/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.3466 - val_loss: 0.3619\n",
      "Epoch 167/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3464 - val_loss: 0.3618\n",
      "Epoch 168/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3463 - val_loss: 0.3616\n",
      "Epoch 169/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3461 - val_loss: 0.3615\n",
      "Epoch 170/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3459 - val_loss: 0.3614\n",
      "Epoch 171/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3458 - val_loss: 0.3613\n",
      "Epoch 172/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3456 - val_loss: 0.3611\n",
      "Epoch 173/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3455 - val_loss: 0.3611\n",
      "Epoch 174/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3453 - val_loss: 0.3609\n",
      "Epoch 175/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3452 - val_loss: 0.3608\n",
      "Epoch 176/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3450 - val_loss: 0.3607\n",
      "Epoch 177/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3449 - val_loss: 0.3606\n",
      "Epoch 178/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3447 - val_loss: 0.3605\n",
      "Epoch 179/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3446 - val_loss: 0.3604\n",
      "Epoch 180/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3445 - val_loss: 0.3603\n",
      "Epoch 181/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3443 - val_loss: 0.3602\n",
      "Epoch 182/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.3442 - val_loss: 0.3601\n",
      "Epoch 183/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3440 - val_loss: 0.3600\n",
      "Epoch 184/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.3439 - val_loss: 0.3599\n",
      "Epoch 185/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.3438 - val_loss: 0.3598\n",
      "Epoch 186/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.3436 - val_loss: 0.3597\n",
      "Epoch 187/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.3435 - val_loss: 0.3596\n",
      "Epoch 188/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3434 - val_loss: 0.3595\n",
      "Epoch 189/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3432 - val_loss: 0.3594\n",
      "Epoch 190/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3431 - val_loss: 0.3593\n",
      "Epoch 191/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.3430 - val_loss: 0.3592\n",
      "Epoch 192/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3429 - val_loss: 0.3591\n",
      "Epoch 193/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3427 - val_loss: 0.3590\n",
      "Epoch 194/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.3426 - val_loss: 0.3589\n",
      "Epoch 195/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.3424 - val_loss: 0.3588\n",
      "Epoch 196/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3423 - val_loss: 0.3587\n",
      "Epoch 197/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3422 - val_loss: 0.3586\n",
      "Epoch 198/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3421 - val_loss: 0.3585\n",
      "Epoch 199/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3419 - val_loss: 0.3584\n",
      "Epoch 200/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3418 - val_loss: 0.3584\n",
      "Epoch 201/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3417 - val_loss: 0.3583\n",
      "Epoch 202/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.3416 - val_loss: 0.3582\n",
      "Epoch 203/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3414 - val_loss: 0.3581\n",
      "Epoch 204/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3413 - val_loss: 0.3580\n",
      "Epoch 205/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3412 - val_loss: 0.3579\n",
      "Epoch 206/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3411 - val_loss: 0.3578\n",
      "Epoch 207/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3409 - val_loss: 0.3577\n",
      "Epoch 208/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3408 - val_loss: 0.3577\n",
      "Epoch 209/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3407 - val_loss: 0.3576\n",
      "Epoch 210/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.3406 - val_loss: 0.3575\n",
      "Epoch 211/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3405 - val_loss: 0.3574\n",
      "Epoch 212/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3404 - val_loss: 0.3573\n",
      "Epoch 213/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3402 - val_loss: 0.3572\n",
      "Epoch 214/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.3401 - val_loss: 0.3572\n",
      "Epoch 215/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.3400 - val_loss: 0.3571\n",
      "Epoch 216/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.3399 - val_loss: 0.3570\n",
      "Epoch 217/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3398 - val_loss: 0.3569\n",
      "Epoch 218/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.3396 - val_loss: 0.3568\n",
      "Epoch 219/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3395 - val_loss: 0.3568\n",
      "Epoch 220/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3394 - val_loss: 0.3567\n",
      "Epoch 221/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3393 - val_loss: 0.3566\n",
      "Epoch 222/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3392 - val_loss: 0.3565\n",
      "Epoch 223/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3391 - val_loss: 0.3565\n",
      "Epoch 224/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3390 - val_loss: 0.3564\n",
      "Epoch 225/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3388 - val_loss: 0.3563\n",
      "Epoch 226/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3387 - val_loss: 0.3562\n",
      "Epoch 227/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3386 - val_loss: 0.3562\n",
      "Epoch 228/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3385 - val_loss: 0.3561\n",
      "Epoch 229/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3384 - val_loss: 0.3561\n",
      "Epoch 230/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3383 - val_loss: 0.3560\n",
      "Epoch 231/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3382 - val_loss: 0.3559\n",
      "Epoch 232/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3381 - val_loss: 0.3559\n",
      "Epoch 233/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3380 - val_loss: 0.3558\n",
      "Epoch 234/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3379 - val_loss: 0.3558\n",
      "Epoch 235/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.3378 - val_loss: 0.3557\n",
      "Epoch 236/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3376 - val_loss: 0.3557\n",
      "Epoch 237/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3375 - val_loss: 0.3556\n",
      "Epoch 238/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3374 - val_loss: 0.3556\n",
      "Epoch 239/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3373 - val_loss: 0.3556\n",
      "Epoch 240/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.3372 - val_loss: 0.3555\n",
      "Epoch 241/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3371 - val_loss: 0.3554\n",
      "Epoch 242/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3370 - val_loss: 0.3554\n",
      "Epoch 243/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3369 - val_loss: 0.3553\n",
      "Epoch 244/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3368 - val_loss: 0.3553\n",
      "Epoch 245/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3367 - val_loss: 0.3553\n",
      "Epoch 246/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3366 - val_loss: 0.3552\n",
      "Epoch 247/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3365 - val_loss: 0.3551\n",
      "Epoch 248/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3363 - val_loss: 0.3551\n",
      "Epoch 249/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3362 - val_loss: 0.3550\n",
      "Epoch 250/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3361 - val_loss: 0.3550\n",
      "Epoch 251/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3360 - val_loss: 0.3550\n",
      "Epoch 252/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3359 - val_loss: 0.3549\n",
      "Epoch 253/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3358 - val_loss: 0.3549\n",
      "Epoch 254/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3357 - val_loss: 0.3549\n",
      "Epoch 255/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3356 - val_loss: 0.3548\n",
      "Epoch 256/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3355 - val_loss: 0.3547\n",
      "Epoch 257/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3354 - val_loss: 0.3548\n",
      "Epoch 258/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3353 - val_loss: 0.3547\n",
      "Epoch 259/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3352 - val_loss: 0.3547\n",
      "Epoch 260/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3351 - val_loss: 0.3546\n",
      "Epoch 261/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3350 - val_loss: 0.3546\n",
      "Epoch 262/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.3349 - val_loss: 0.3545\n",
      "Epoch 263/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.3348 - val_loss: 0.3545\n",
      "Epoch 264/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.3347 - val_loss: 0.3545\n",
      "Epoch 265/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3346 - val_loss: 0.3544\n",
      "Epoch 266/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3345 - val_loss: 0.3544\n",
      "Epoch 267/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3344 - val_loss: 0.3544\n",
      "Epoch 268/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.3343 - val_loss: 0.3544\n",
      "Epoch 269/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3342 - val_loss: 0.3543\n",
      "Epoch 270/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3341 - val_loss: 0.3543\n",
      "Epoch 271/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3340 - val_loss: 0.3543\n",
      "Epoch 272/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3339 - val_loss: 0.3543\n",
      "Epoch 273/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3338 - val_loss: 0.3541\n",
      "Epoch 274/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3337 - val_loss: 0.3541\n",
      "Epoch 275/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3336 - val_loss: 0.3541\n",
      "Epoch 276/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3335 - val_loss: 0.3540\n",
      "Epoch 277/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.3334 - val_loss: 0.3540\n",
      "Epoch 278/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3333 - val_loss: 0.3539\n",
      "Epoch 279/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3332 - val_loss: 0.3539\n",
      "Epoch 280/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3331 - val_loss: 0.3539\n",
      "Epoch 281/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3330 - val_loss: 0.3538\n",
      "Epoch 282/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3329 - val_loss: 0.3538\n",
      "Epoch 283/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.3328 - val_loss: 0.3538\n",
      "Epoch 284/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.3327 - val_loss: 0.3537\n",
      "Epoch 285/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3326 - val_loss: 0.3536\n",
      "Epoch 286/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.3325 - val_loss: 0.3537\n",
      "Epoch 287/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3325 - val_loss: 0.3536\n",
      "Epoch 288/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3324 - val_loss: 0.3535\n",
      "Epoch 289/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3323 - val_loss: 0.3535\n",
      "Epoch 290/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3322 - val_loss: 0.3535\n",
      "Epoch 291/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3321 - val_loss: 0.3533\n",
      "Epoch 292/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3320 - val_loss: 0.3532\n",
      "Epoch 293/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3319 - val_loss: 0.3530\n",
      "Epoch 294/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3318 - val_loss: 0.3529\n",
      "Epoch 295/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.3317 - val_loss: 0.3527\n",
      "Epoch 296/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.3316 - val_loss: 0.3525\n",
      "Epoch 297/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3316 - val_loss: 0.3524\n",
      "Epoch 298/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.3315 - val_loss: 0.3523\n",
      "Epoch 299/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3314 - val_loss: 0.3522\n",
      "Epoch 300/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3313 - val_loss: 0.3520\n",
      "Epoch 301/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3312 - val_loss: 0.3520\n",
      "Epoch 302/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3311 - val_loss: 0.3518\n",
      "Epoch 303/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3310 - val_loss: 0.3517\n",
      "Epoch 304/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3309 - val_loss: 0.3516\n",
      "Epoch 305/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3308 - val_loss: 0.3515\n",
      "Epoch 306/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.3307 - val_loss: 0.3514\n",
      "Epoch 307/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.3306 - val_loss: 0.3513\n",
      "Epoch 308/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3305 - val_loss: 0.3512\n",
      "Epoch 309/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.3304 - val_loss: 0.3511\n",
      "Epoch 310/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3304 - val_loss: 0.3510\n",
      "Epoch 311/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3303 - val_loss: 0.3509\n",
      "Epoch 312/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3302 - val_loss: 0.3508\n",
      "Epoch 313/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3301 - val_loss: 0.3508\n",
      "Epoch 314/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3300 - val_loss: 0.3507\n",
      "Epoch 315/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3299 - val_loss: 0.3506\n",
      "Epoch 316/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3298 - val_loss: 0.3505\n",
      "Epoch 317/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3297 - val_loss: 0.3505\n",
      "Epoch 318/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3297 - val_loss: 0.3504\n",
      "Epoch 319/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3296 - val_loss: 0.3503\n",
      "Epoch 320/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3295 - val_loss: 0.3503\n",
      "Epoch 321/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.3294 - val_loss: 0.3502\n",
      "Epoch 322/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3293 - val_loss: 0.3501\n",
      "Epoch 323/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3292 - val_loss: 0.3500\n",
      "Epoch 324/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.3291 - val_loss: 0.3499\n",
      "Epoch 325/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3290 - val_loss: 0.3499\n",
      "Epoch 326/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3289 - val_loss: 0.3498\n",
      "Epoch 327/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - loss: 0.3288 - val_loss: 0.3498\n",
      "Epoch 328/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3287 - val_loss: 0.3497\n",
      "Epoch 329/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.3286 - val_loss: 0.3497\n",
      "Epoch 330/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3286 - val_loss: 0.3497\n",
      "Epoch 331/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3285 - val_loss: 0.3496\n",
      "Epoch 332/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3284 - val_loss: 0.3496\n",
      "Epoch 333/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.3283 - val_loss: 0.3496\n",
      "Epoch 334/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3282 - val_loss: 0.3496\n",
      "Epoch 335/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3281 - val_loss: 0.3495\n",
      "Epoch 336/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3280 - val_loss: 0.3495\n",
      "Epoch 337/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3279 - val_loss: 0.3495\n",
      "Epoch 338/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3278 - val_loss: 0.3495\n",
      "Epoch 339/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3277 - val_loss: 0.3494\n",
      "Epoch 340/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3277 - val_loss: 0.3494\n",
      "Epoch 341/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3276 - val_loss: 0.3494\n",
      "Epoch 342/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3275 - val_loss: 0.3493\n",
      "Epoch 343/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.3274 - val_loss: 0.3493\n",
      "Epoch 344/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3273 - val_loss: 0.3492\n",
      "Epoch 345/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3272 - val_loss: 0.3492\n",
      "Epoch 346/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3271 - val_loss: 0.3492\n",
      "Epoch 347/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3270 - val_loss: 0.3491\n",
      "Epoch 348/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.3269 - val_loss: 0.3491\n",
      "Epoch 349/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3269 - val_loss: 0.3490\n",
      "Epoch 350/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3268 - val_loss: 0.3490\n",
      "Epoch 351/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3267 - val_loss: 0.3489\n",
      "Epoch 352/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3266 - val_loss: 0.3489\n",
      "Epoch 353/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3265 - val_loss: 0.3488\n",
      "Epoch 354/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3264 - val_loss: 0.3488\n",
      "Epoch 355/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3263 - val_loss: 0.3487\n",
      "Epoch 356/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3263 - val_loss: 0.3487\n",
      "Epoch 357/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.3262 - val_loss: 0.3487\n",
      "Epoch 358/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3261 - val_loss: 0.3486\n",
      "Epoch 359/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3260 - val_loss: 0.3486\n",
      "Epoch 360/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.3259 - val_loss: 0.3485\n",
      "Epoch 361/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3258 - val_loss: 0.3485\n",
      "Epoch 362/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.3257 - val_loss: 0.3484\n",
      "Epoch 363/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3256 - val_loss: 0.3484\n",
      "Epoch 364/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3256 - val_loss: 0.3483\n",
      "Epoch 365/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3255 - val_loss: 0.3482\n",
      "Epoch 366/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3254 - val_loss: 0.3481\n",
      "Epoch 367/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.3253 - val_loss: 0.3481\n",
      "Epoch 368/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.3252 - val_loss: 0.3481\n",
      "Epoch 369/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3252 - val_loss: 0.3480\n",
      "Epoch 370/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3251 - val_loss: 0.3480\n",
      "Epoch 371/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3250 - val_loss: 0.3480\n",
      "Epoch 372/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3249 - val_loss: 0.3479\n",
      "Epoch 373/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3248 - val_loss: 0.3479\n",
      "Epoch 374/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3248 - val_loss: 0.3479\n",
      "Epoch 375/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.3247 - val_loss: 0.3479\n",
      "Epoch 376/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3246 - val_loss: 0.3479\n",
      "Epoch 377/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3245 - val_loss: 0.3478\n",
      "Epoch 378/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3245 - val_loss: 0.3478\n",
      "Epoch 379/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3244 - val_loss: 0.3478\n",
      "Epoch 380/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3243 - val_loss: 0.3478\n",
      "Epoch 381/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3242 - val_loss: 0.3477\n",
      "Epoch 382/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3242 - val_loss: 0.3477\n",
      "Epoch 383/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.3241 - val_loss: 0.3476\n",
      "Epoch 384/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - loss: 0.3240 - val_loss: 0.3476\n",
      "Epoch 385/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3240 - val_loss: 0.3476\n",
      "Epoch 386/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.3239 - val_loss: 0.3476\n",
      "Epoch 387/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3238 - val_loss: 0.3475\n",
      "Epoch 388/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3238 - val_loss: 0.3475\n",
      "Epoch 389/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3237 - val_loss: 0.3475\n",
      "Epoch 390/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3236 - val_loss: 0.3474\n",
      "Epoch 391/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3236 - val_loss: 0.3474\n",
      "Epoch 392/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3235 - val_loss: 0.3474\n",
      "Epoch 393/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3234 - val_loss: 0.3473\n",
      "Epoch 394/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3234 - val_loss: 0.3473\n",
      "Epoch 395/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3233 - val_loss: 0.3473\n",
      "Epoch 396/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3232 - val_loss: 0.3472\n",
      "Epoch 397/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3231 - val_loss: 0.3472\n",
      "Epoch 398/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.3231 - val_loss: 0.3472\n",
      "Epoch 399/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3230 - val_loss: 0.3471\n",
      "Epoch 400/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3229 - val_loss: 0.3471\n",
      "Epoch 401/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.3229 - val_loss: 0.3471\n",
      "Epoch 402/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3228 - val_loss: 0.3470\n",
      "Epoch 403/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.3228 - val_loss: 0.3470\n",
      "Epoch 404/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3227 - val_loss: 0.3469\n",
      "Epoch 405/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.3226 - val_loss: 0.3469\n",
      "Epoch 406/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3225 - val_loss: 0.3468\n",
      "Epoch 407/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3224 - val_loss: 0.3468\n",
      "Epoch 408/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3224 - val_loss: 0.3467\n",
      "Epoch 409/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.3223 - val_loss: 0.3467\n",
      "Epoch 410/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3222 - val_loss: 0.3467\n",
      "Epoch 411/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3221 - val_loss: 0.3467\n",
      "Epoch 412/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3220 - val_loss: 0.3466\n",
      "Epoch 413/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3220 - val_loss: 0.3466\n",
      "Epoch 414/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.3219 - val_loss: 0.3465\n",
      "Epoch 415/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3218 - val_loss: 0.3465\n",
      "Epoch 416/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3217 - val_loss: 0.3464\n",
      "Epoch 417/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3217 - val_loss: 0.3464\n",
      "Epoch 418/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.3216 - val_loss: 0.3464\n",
      "Epoch 419/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3215 - val_loss: 0.3463\n",
      "Epoch 420/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3214 - val_loss: 0.3463\n",
      "Epoch 421/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3214 - val_loss: 0.3463\n",
      "Epoch 422/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.3213 - val_loss: 0.3462\n",
      "Epoch 423/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.3212 - val_loss: 0.3461\n",
      "Epoch 424/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.3211 - val_loss: 0.3461\n",
      "Epoch 425/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3211 - val_loss: 0.3461\n",
      "Epoch 426/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3210 - val_loss: 0.3460\n",
      "Epoch 427/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3209 - val_loss: 0.3460\n",
      "Epoch 428/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3208 - val_loss: 0.3459\n",
      "Epoch 429/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.3208 - val_loss: 0.3459\n",
      "Epoch 430/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3207 - val_loss: 0.3459\n",
      "Epoch 431/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3206 - val_loss: 0.3458\n",
      "Epoch 432/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3205 - val_loss: 0.3457\n",
      "Epoch 433/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3204 - val_loss: 0.3457\n",
      "Epoch 434/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3204 - val_loss: 0.3456\n",
      "Epoch 435/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.3203 - val_loss: 0.3456\n",
      "Epoch 436/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3202 - val_loss: 0.3455\n",
      "Epoch 437/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3201 - val_loss: 0.3454\n",
      "Epoch 438/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3201 - val_loss: 0.3454\n",
      "Epoch 439/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3200 - val_loss: 0.3453\n",
      "Epoch 440/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.3199 - val_loss: 0.3452\n",
      "Epoch 441/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.3198 - val_loss: 0.3452\n",
      "Epoch 442/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3197 - val_loss: 0.3451\n",
      "Epoch 443/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3196 - val_loss: 0.3451\n",
      "Epoch 444/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3195 - val_loss: 0.3450\n",
      "Epoch 445/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.3194 - val_loss: 0.3451\n",
      "Epoch 446/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3193 - val_loss: 0.3450\n",
      "Epoch 447/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3192 - val_loss: 0.3450\n",
      "Epoch 448/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.3191 - val_loss: 0.3450\n",
      "Epoch 449/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3190 - val_loss: 0.3450\n",
      "Epoch 450/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.3189 - val_loss: 0.3450\n"
     ]
    }
   ],
   "source": [
    "# Despues de cada epoch, guardamos el modelo, solo la mejor version. Sirve para evitar fallas de si se va la luz o lo que sea\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.keras\",save_best_only=True)\n",
    "# Usamos una funcion para que el modelo pare mediante una funcion\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(X_train,y_train,epochs=10000,callbacks=[checkpoint_cb,early_stopping_cb],validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2515ec0f1a0>,\n",
       " <matplotlib.lines.Line2D at 0x2515ec64050>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46708470582962036"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.9390128],\n",
       "       [2.6286027],\n",
       "       [1.6396475]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nueva = X_test[:3]\n",
    "y_nueva = model.predict(X_nueva)\n",
    "y_nueva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el modelo\n",
    "\n",
    "Usar las extensiones .h5 o .keras, aunque .h5 está siendo deprecado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelito.keras\")\n",
    "# Cargar\n",
    "# model = keras.models.load_model(\"modelito.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
